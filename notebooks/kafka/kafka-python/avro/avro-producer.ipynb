{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Kafka Avro Producer \n",
    "\n",
    "**Technical Accomplishments:**\n",
    "- Start working with avro schema in Kafka\n",
    "- Introduce the class `AvroProducer`\n",
    "- Produce data for a Kafka avro topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's start importing libraries and creating useful variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroProducer\n",
    "import time\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "\n",
    "#import qcutils\n",
    "\n",
    "servers=\"broker:29092\"\n",
    "\n",
    "sr_url=\"http://schema-registry:8081\"\n",
    "\n",
    "topic = 'avro-producer'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_client = AdminClient({\n",
    "    \"bootstrap.servers\": servers\n",
    "})\n",
    "\n",
    "topic_list = []\n",
    "topic_list.append(NewTopic(topic, 1, 1))\n",
    "admin_client.create_topics(topic_list)\n",
    "\n",
    "producerconf = {\n",
    "        'bootstrap.servers': servers,\n",
    "        'schema.registry.url': sr_url\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in order to avoid conflicts during write operation, please name the topic as `<surname>-topic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's start importing libraries and creating useful variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avro Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonKey\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"name\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "value_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonValue\",\n",
    "  \"fields\": \n",
    "    [{\n",
    "      \"name\": \"age\",\n",
    "      \"type\": \"int\",\n",
    "      \"default\": 18\n",
    "    }]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "key_schema = avro.loads(key_schema_str)\n",
    "value_schema = avro.loads(value_schema_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AvroProducer(producerconf, default_key_schema=key_schema, default_value_schema=value_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 0}\n",
      "{'age': 1}\n",
      "Produced record to topic avro-producer partition [0] @ offset 0\n",
      "{'age': 2}\n",
      "Produced record to topic avro-producer partition [0] @ offset 1\n",
      "{'age': 3}\n",
      "Produced record to topic avro-producer partition [0] @ offset 2\n",
      "{'age': 4}\n",
      "Produced record to topic avro-producer partition [0] @ offset 3\n",
      "{'age': 5}\n",
      "Produced record to topic avro-producer partition [0] @ offset 4\n",
      "{'age': 6}\n",
      "Produced record to topic avro-producer partition [0] @ offset 5\n",
      "{'age': 7}\n",
      "Produced record to topic avro-producer partition [0] @ offset 6\n",
      "{'age': 8}\n",
      "Produced record to topic avro-producer partition [0] @ offset 7\n",
      "{'age': 9}\n",
      "Produced record to topic avro-producer partition [0] @ offset 8\n",
      "{'age': 10}\n",
      "Produced record to topic avro-producer partition [0] @ offset 9\n",
      "{'age': 11}\n",
      "Produced record to topic avro-producer partition [0] @ offset 10\n",
      "{'age': 12}\n",
      "Produced record to topic avro-producer partition [0] @ offset 11\n",
      "{'age': 13}\n",
      "Produced record to topic avro-producer partition [0] @ offset 12\n",
      "{'age': 14}\n",
      "Produced record to topic avro-producer partition [0] @ offset 13\n",
      "{'age': 15}\n",
      "Produced record to topic avro-producer partition [0] @ offset 14\n",
      "{'age': 16}\n",
      "Produced record to topic avro-producer partition [0] @ offset 15\n",
      "{'age': 17}\n",
      "Produced record to topic avro-producer partition [0] @ offset 16\n",
      "{'age': 18}\n",
      "Produced record to topic avro-producer partition [0] @ offset 17\n",
      "{'age': 19}\n",
      "Produced record to topic avro-producer partition [0] @ offset 18\n",
      "{'age': 20}\n",
      "Produced record to topic avro-producer partition [0] @ offset 19\n",
      "{'age': 21}\n",
      "Produced record to topic avro-producer partition [0] @ offset 20\n",
      "{'age': 22}\n",
      "Produced record to topic avro-producer partition [0] @ offset 21\n",
      "{'age': 23}\n",
      "Produced record to topic avro-producer partition [0] @ offset 22\n",
      "{'age': 24}\n",
      "Produced record to topic avro-producer partition [0] @ offset 23\n",
      "{'age': 25}\n",
      "Produced record to topic avro-producer partition [0] @ offset 24\n",
      "{'age': 26}\n",
      "Produced record to topic avro-producer partition [0] @ offset 25\n",
      "{'age': 27}\n",
      "Produced record to topic avro-producer partition [0] @ offset 26\n",
      "{'age': 28}\n",
      "Produced record to topic avro-producer partition [0] @ offset 27\n",
      "{'age': 29}\n",
      "Produced record to topic avro-producer partition [0] @ offset 28\n",
      "{'age': 30}\n",
      "Produced record to topic avro-producer partition [0] @ offset 29\n",
      "{'age': 31}\n",
      "Produced record to topic avro-producer partition [0] @ offset 30\n",
      "{'age': 32}\n",
      "Produced record to topic avro-producer partition [0] @ offset 31\n",
      "{'age': 33}\n",
      "Produced record to topic avro-producer partition [0] @ offset 32\n",
      "{'age': 34}\n",
      "Produced record to topic avro-producer partition [0] @ offset 33\n",
      "{'age': 35}\n",
      "Produced record to topic avro-producer partition [0] @ offset 34\n",
      "{'age': 36}\n",
      "Produced record to topic avro-producer partition [0] @ offset 35\n",
      "{'age': 37}\n",
      "Produced record to topic avro-producer partition [0] @ offset 36\n",
      "{'age': 38}\n",
      "Produced record to topic avro-producer partition [0] @ offset 37\n",
      "{'age': 39}\n",
      "Produced record to topic avro-producer partition [0] @ offset 38\n",
      "{'age': 40}\n",
      "Produced record to topic avro-producer partition [0] @ offset 39\n",
      "{'age': 41}\n",
      "Produced record to topic avro-producer partition [0] @ offset 40\n",
      "{'age': 42}\n",
      "Produced record to topic avro-producer partition [0] @ offset 41\n",
      "{'age': 43}\n",
      "Produced record to topic avro-producer partition [0] @ offset 42\n",
      "{'age': 44}\n",
      "Produced record to topic avro-producer partition [0] @ offset 43\n",
      "{'age': 45}\n",
      "Produced record to topic avro-producer partition [0] @ offset 44\n",
      "{'age': 46}\n",
      "Produced record to topic avro-producer partition [0] @ offset 45\n",
      "{'age': 47}\n",
      "Produced record to topic avro-producer partition [0] @ offset 46\n",
      "{'age': 48}\n",
      "Produced record to topic avro-producer partition [0] @ offset 47\n",
      "{'age': 49}\n",
      "Produced record to topic avro-producer partition [0] @ offset 48\n",
      "{'age': 50}\n",
      "Produced record to topic avro-producer partition [0] @ offset 49\n",
      "{'age': 51}\n",
      "Produced record to topic avro-producer partition [0] @ offset 50\n",
      "{'age': 52}\n",
      "Produced record to topic avro-producer partition [0] @ offset 51\n",
      "{'age': 53}\n",
      "Produced record to topic avro-producer partition [0] @ offset 52\n",
      "{'age': 54}\n",
      "Produced record to topic avro-producer partition [0] @ offset 53\n",
      "{'age': 55}\n",
      "Produced record to topic avro-producer partition [0] @ offset 54\n",
      "{'age': 56}\n",
      "Produced record to topic avro-producer partition [0] @ offset 55\n",
      "{'age': 57}\n",
      "Produced record to topic avro-producer partition [0] @ offset 56\n",
      "{'age': 58}\n",
      "Produced record to topic avro-producer partition [0] @ offset 57\n",
      "{'age': 59}\n",
      "Produced record to topic avro-producer partition [0] @ offset 58\n",
      "{'age': 60}\n",
      "Produced record to topic avro-producer partition [0] @ offset 59\n",
      "{'age': 61}\n",
      "Produced record to topic avro-producer partition [0] @ offset 60\n",
      "{'age': 62}\n",
      "Produced record to topic avro-producer partition [0] @ offset 61\n",
      "{'age': 63}\n",
      "Produced record to topic avro-producer partition [0] @ offset 62\n",
      "{'age': 64}\n",
      "Produced record to topic avro-producer partition [0] @ offset 63\n",
      "{'age': 65}\n",
      "Produced record to topic avro-producer partition [0] @ offset 64\n",
      "{'age': 66}\n",
      "Produced record to topic avro-producer partition [0] @ offset 65\n",
      "{'age': 67}\n",
      "Produced record to topic avro-producer partition [0] @ offset 66\n",
      "{'age': 68}\n",
      "Produced record to topic avro-producer partition [0] @ offset 67\n",
      "{'age': 69}\n",
      "Produced record to topic avro-producer partition [0] @ offset 68\n",
      "{'age': 70}\n",
      "Produced record to topic avro-producer partition [0] @ offset 69\n",
      "{'age': 71}\n",
      "Produced record to topic avro-producer partition [0] @ offset 70\n",
      "{'age': 72}\n",
      "Produced record to topic avro-producer partition [0] @ offset 71\n",
      "{'age': 73}\n",
      "Produced record to topic avro-producer partition [0] @ offset 72\n",
      "{'age': 74}\n",
      "Produced record to topic avro-producer partition [0] @ offset 73\n",
      "{'age': 75}\n",
      "Produced record to topic avro-producer partition [0] @ offset 74\n",
      "{'age': 76}\n",
      "Produced record to topic avro-producer partition [0] @ offset 75\n",
      "{'age': 77}\n",
      "Produced record to topic avro-producer partition [0] @ offset 76\n",
      "{'age': 78}\n",
      "Produced record to topic avro-producer partition [0] @ offset 77\n",
      "{'age': 79}\n",
      "Produced record to topic avro-producer partition [0] @ offset 78\n",
      "{'age': 80}\n",
      "Produced record to topic avro-producer partition [0] @ offset 79\n",
      "{'age': 81}\n",
      "Produced record to topic avro-producer partition [0] @ offset 80\n",
      "{'age': 82}\n",
      "Produced record to topic avro-producer partition [0] @ offset 81\n",
      "{'age': 83}\n",
      "Produced record to topic avro-producer partition [0] @ offset 82\n",
      "{'age': 84}\n",
      "Produced record to topic avro-producer partition [0] @ offset 83\n",
      "{'age': 85}\n",
      "Produced record to topic avro-producer partition [0] @ offset 84\n",
      "{'age': 86}\n",
      "Produced record to topic avro-producer partition [0] @ offset 85\n",
      "{'age': 87}\n",
      "Produced record to topic avro-producer partition [0] @ offset 86\n",
      "{'age': 88}\n",
      "Produced record to topic avro-producer partition [0] @ offset 87\n",
      "{'age': 89}\n",
      "Produced record to topic avro-producer partition [0] @ offset 88\n",
      "{'age': 90}\n",
      "Produced record to topic avro-producer partition [0] @ offset 89\n",
      "{'age': 91}\n",
      "Produced record to topic avro-producer partition [0] @ offset 90\n",
      "{'age': 92}\n",
      "Produced record to topic avro-producer partition [0] @ offset 91\n",
      "{'age': 93}\n",
      "Produced record to topic avro-producer partition [0] @ offset 92\n",
      "{'age': 94}\n",
      "Produced record to topic avro-producer partition [0] @ offset 93\n",
      "{'age': 95}\n",
      "Produced record to topic avro-producer partition [0] @ offset 94\n",
      "{'age': 96}\n",
      "Produced record to topic avro-producer partition [0] @ offset 95\n",
      "{'age': 97}\n",
      "Produced record to topic avro-producer partition [0] @ offset 96\n",
      "{'age': 98}\n",
      "Produced record to topic avro-producer partition [0] @ offset 97\n",
      "{'age': 99}\n",
      "Produced record to topic avro-producer partition [0] @ offset 98\n",
      "Produced record to topic avro-producer partition [0] @ offset 99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = {\"name\": \"Abe\"}\n",
    "\n",
    "def cb(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "#sr_url=qcutils.read_config_value(\"kafka.schema_registry.url\")\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, 100):\n",
    "    value = {\"age\": i}\n",
    "    ap.produce(topic=topic, value=value, key=key, key_schema=key_schema, value_schema=value_schema, callback=cb)\n",
    "    print(value)\n",
    "    ap.poll(0)\n",
    "    time.sleep(1)\n",
    "    \n",
    "ap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avro Producer with Evolving Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "Incompatible Avro schema:409 message:{'error_code': 409, 'message': 'Schema being registered is incompatible with an earlier schema for subject \"avro-producer-value\"'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5962d05b32fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Abe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"age\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"haircolor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhairColor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_schema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_schema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/confluent_kafka/avro/__init__.py\u001b[0m in \u001b[0;36mproduce\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue_schema\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_record_with_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueSerializerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avro schema required for values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/confluent_kafka/avro/serializer/message_serializer.py\u001b[0m in \u001b[0;36mencode_record_with_schema\u001b[0;34m(self, topic, schema, record, is_key)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_register_schemas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# register it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mschema_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mschema_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_registration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/confluent_kafka/avro/cached_schema_registry_client.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, subject, avro_schema)\u001b[0m\n\u001b[1;32m    219\u001b[0m                               + \" message:\" + str(result))\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             raise ClientError(\"Incompatible Avro schema:\" + str(code)\n\u001b[0m\u001b[1;32m    222\u001b[0m                               + \" message:\" + str(result))\n\u001b[1;32m    223\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m422\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: Incompatible Avro schema:409 message:{'error_code': 409, 'message': 'Schema being registered is incompatible with an earlier schema for subject \"avro-producer-value\"'}"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroProducer\n",
    "import time\n",
    "\n",
    "key_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonKey\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"name\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "value_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonValue\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"name\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"age\",\n",
    "      \"type\": \"int\",\n",
    "      \"default\": 18\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"haircolor\",\n",
    "      \"type\": \"string\",\n",
    "      \"default\": \"black\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "key_schema = avro.loads(key_schema_str)\n",
    "value_schema = avro.loads(value_schema_str)\n",
    "\n",
    "key = {\"name\": \"Abe\"}\n",
    "\n",
    "def cb(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "producerconf = {\n",
    "        'bootstrap.servers': servers,\n",
    "        'schema.registry.url': sr_url\n",
    "    }\n",
    "        \n",
    "ap = AvroProducer(producerconf, default_key_schema=key_schema, default_value_schema=value_schema)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    if i < 40:\n",
    "        hairColor = \"black\"\n",
    "    elif (i >=40 and i < 55):\n",
    "        hairColor = \"grizzled\"\n",
    "    else:\n",
    "        hairColor = \"white\"\n",
    "  \n",
    "    value = {\"name\": \"Abe\", \"age\": i, \"haircolor\": hairColor}\n",
    "    ap.produce(topic=topic, value=value, key=key, key_schema=key_schema, value_schema=value_schema, callback=cb)\n",
    "    print(value)\n",
    "    ap.poll(0)\n",
    "    time.sleep(1)\n",
    "\n",
    "ap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** In order to add SASL security for the connection to the kafka broker, you need to add security configurations.\n",
    "\n",
    "```\n",
    "username=qcutils.read_config_value(\"kafka.access.key\")\n",
    "password=qcutils.read_config_value(\"kafka.access.secret\")\n",
    "\n",
    "sr_user_info=qcutils.read_config_value(\"kafka.schema_registry.key\") + \":\" + qcutils.read_config_value(\"kafka.schema_registry.secret\")\n",
    "\n",
    "producerconf = {\n",
    "        'bootstrap.servers': <servers>,\n",
    "        'sasl.mechanisms': 'PLAIN',\n",
    "        'security.protocol': 'SASL_SSL',\n",
    "        'sasl.username': <username>,\n",
    "        'sasl.password': <password>,\n",
    "        'schema.registry.url': sr_url,\n",
    "        'schema.registry.basic.auth.credentials.source': 'USER_INFO',\n",
    "        'schema.registry.basic.auth.user.info': <login-info>\n",
    "    }\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "name": "avro-producer",
  "notebookId": 1507370365633616
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
